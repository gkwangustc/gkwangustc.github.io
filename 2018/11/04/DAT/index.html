<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.5.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.5.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.5.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.5.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.5.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.5.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="前言这是Ma Chao大神发表在NIPS 2018上的一篇论文，从代码来看是MDNet的改进版，与CVPR 2018和ECCV 2018的趋势一样，这篇论文也在跟踪框架中使用了Attention，不过与其他论文不同的是，本篇论文的Attention并不是通过在网络加入一个module来学习得到的，而是将BP得到的梯度作为Attention，并将其作为一个Loss函数的正则项来调整网络的训练过程，比">
<meta name="keywords" content="paper, visual tracking">
<meta property="og:type" content="article">
<meta property="og:title" content="论文笔记 - &quot;Deep Attentive Tracking via Reciprocative Learning">
<meta property="og:url" content="http://www.gkwang.space/2018/11/04/DAT/index.html">
<meta property="og:site_name" content="NERV">
<meta property="og:description" content="前言这是Ma Chao大神发表在NIPS 2018上的一篇论文，从代码来看是MDNet的改进版，与CVPR 2018和ECCV 2018的趋势一样，这篇论文也在跟踪框架中使用了Attention，不过与其他论文不同的是，本篇论文的Attention并不是通过在网络加入一个module来学习得到的，而是将BP得到的梯度作为Attention，并将其作为一个Loss函数的正则项来调整网络的训练过程，比">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://www.gkwang.space/images/DAT/Pipeline.png">
<meta property="og:image" content="http://www.gkwang.space/images/DAT/reciprocative_learning.png">
<meta property="og:image" content="http://www.gkwang.space/images/DAT/contrast.png">
<meta property="og:image" content="http://www.gkwang.space/images/DAT/table1.png">
<meta property="og:image" content="http://www.gkwang.space/images/DAT/table2.png">
<meta property="og:image" content="http://www.gkwang.space/images/DAT/table3.png">
<meta property="og:image" content="http://www.gkwang.space/images/DAT/OTB.png">
<meta property="og:image" content="http://www.gkwang.space/images/DAT/VOT.png">
<meta property="og:updated_time" content="2018-11-04T13:51:25.757Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="论文笔记 - &quot;Deep Attentive Tracking via Reciprocative Learning">
<meta name="twitter:description" content="前言这是Ma Chao大神发表在NIPS 2018上的一篇论文，从代码来看是MDNet的改进版，与CVPR 2018和ECCV 2018的趋势一样，这篇论文也在跟踪框架中使用了Attention，不过与其他论文不同的是，本篇论文的Attention并不是通过在网络加入一个module来学习得到的，而是将BP得到的梯度作为Attention，并将其作为一个Loss函数的正则项来调整网络的训练过程，比">
<meta name="twitter:image" content="http://www.gkwang.space/images/DAT/Pipeline.png">






  <link rel="canonical" href="http://www.gkwang.space/2018/11/04/DAT/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>论文笔记 - "Deep Attentive Tracking via Reciprocative Learning | NERV</title>
  






  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?de075a211f136f9f5ea851d6c6353b3b";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">NERV</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>
  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.gkwang.space/2018/11/04/DAT/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="王国坤">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="NERV">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">论文笔记 - "Deep Attentive Tracking via Reciprocative Learning
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-11-04 21:50:04 / Modified: 21:51:25" itemprop="dateCreated datePublished" datetime="2018-11-04T21:50:04+08:00">2018-11-04</time>
            

            
              

              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>这是Ma Chao大神发表在NIPS 2018上的一篇论文，从代码来看是MDNet的改进版，与CVPR 2018和ECCV 2018的趋势一样，这篇论文也在跟踪框架中使用了Attention，不过与其他论文不同的是，本篇论文的Attention并不是通过在网络加入一个module来学习得到的，而是将BP得到的梯度作为Attention，并将其作为一个Loss函数的正则项来调整网络的训练过程，比较有新意。</p>
<p>论文：<a href="https://arxiv.org/pdf/1810.03851.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1810.03851.pdf</a></p>
<p>源码：<a href="https://github.com/shipubupt/NIPS2018" target="_blank" rel="noopener">https://github.com/shipubupt/NIPS2018</a></p>
<a id="more"></a>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>一般来说，tracking和detection类似，可以分为one-stage和two-stage两种。代表性的one-stage方法一般基于DCF方法，通过相关滤波器在特征上卷积得到heat map，最高点即为目标所在位置。two-stage方法一般为判别方法，即先在图像中产生proposal，然后通过分类器来给proposal打分，最高的proposal即为目标所在位置，如SVM，CNN-SVM等。</p>
<p>这两种方法都可以通过Attention提高tracker的性能，在one-stage方法中，在输入特征上加Gaussian或者Cosine窗函数来抑制目标周围的特征，让DCF专注于图片中心的目标，可以视为一种简单的Attention，但是当物体有较大位移时，这样的Attention就没有太大用处，而且抑制边缘的背景特征，也会丢掉一些有用的信息；在two-stage方法中，Attention更常用于特征选择，在end-to-end的训练框架中，通过Attention模块的选择作用，可以增强特征的表达能力，提高tracker性能，但是在单帧上学习得到的attention在持续的跟踪过程中并不鲁棒，由于无法自适应的调整，一些微小的错误就会导致累积效应，从而限制了tracker的性能。</p>
<h3 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h3><p>本文提出了一种交互学习算法来探索attention在two-stage的跟踪算法中的应用。与现有的two-stage算法不同，本文的attention并不是通过一个额外的attention module计算得到的，作者直接从分类网络中得到attention信息。</p>
<p>首先作者将图像输入网络进行前传，得到classification score，然后进行反传，得到每一层的梯度，但是在反传的过程中，网络的参数并没有更新，仅仅是为了计算得到第一个卷积层的梯度，并将其作为attention map，加入到loss函数中。然后使用这个loss函数来训练网络。跟踪时，直接使用前传得到的分数来判断每个proposal是否为目标。</p>
<p>本文的创新点可以概括为</p>
<ul>
<li>提出了一个交互学习的算法，来计算tracking-by-detection框架中的attention</li>
<li>将attention map作为Loss函数中的正则项来训练分类器，让其聚焦于时序鲁邦的特征</li>
<li>作者在各大benchmark上进行测试，性能和state-of-the-art的方法性能相当。</li>
</ul>
<h3 id="本文提出的方法"><a href="#本文提出的方法" class="headerlink" title="本文提出的方法"></a>本文提出的方法</h3><p>本文的框架图如图所示：</p>
<p><img src="/images/DAT/Pipeline.png" alt="Pipeline"></p>
<h4 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h4><p>对于一个基于CNN的track-by-detection框架，我们假设输入为$I$，输出为score向量，每个元素代表I输入属于$c$类的概率。对于一个给定的输入图片$I_0$，使用一阶的泰勒在点$z_0$处对映射函数$f_c(I)$进行泰勒展开，可以得到：</p>
<script type="math/tex; mode=display">
f_c(I) \approx A_{c}^{\top} I + B</script><p>点$z_0$是$I_0$的去心邻域中的一点，对于$I_0$去心邻域中的任何一点，上述等式都成立。而由于$I_0$和$z_0$足够近，因此两点的梯度相同，在上式中$A_c$为偏导数，即函数在$I_0$处的梯度</p>
<script type="math/tex; mode=display">
A_c = \frac{\partial f_c(I)}{\partial I}\mid_{I=I_0}</script><p>此外，从等式1中可以看出，映射函数求出的score收到$A_c$的影响，所以$A_c$也反映了$I_0$对score的重要性有多大，因此$A_c$可以被视为一种attention map</p>
<p>求解attention map时，需要按照等式2来得到输入$I_0$的梯度，所以过程分两步进行，首先将$I_0$输入网络中，并进行反传，取第一层的梯度，并且只保留正值来作为attention map，因为正值可以清晰的反应$I_0$中每一部分对分数的贡献。在这个BP过程中，网络参数是不更新的</p>
<h4 id="Attention的正则化"><a href="#Attention的正则化" class="headerlink" title="Attention的正则化"></a>Attention的正则化</h4><p>在tracking-by-detection框架中，一般通过分类器将目标标记为正类，将背景标记为负类，如果将目标样本求得的attention map即为$A_p$，将背景样本求得的attention map记为$A_n$的话，我们希望$A_p$越大越好，$A_n$越小越好。因此，我们定义了如下的正则项，对于正样本：</p>
<script type="math/tex; mode=display">
R_{(y=1)} = \frac {\sigma_{A_p}} {\mu_{A_p}} + \frac {\mu_{A_n}} {\sigma_{A_n}}</script><p>对于负样本：</p>
<script type="math/tex; mode=display">
R_{(y=0)} = \frac {\sigma_{A_n}} {\mu_{A_n}} + \frac {\mu_{A_p}} {\sigma_{A_p}}</script><p>相应的分类Loss函数调整为：</p>
<script type="math/tex; mode=display">
\mathcal{L} = \mathcal{L}_{CE} + \lambda \cdot \left [ y \cdot R_{(y=1)} + (1 - y) \cdot R_{(y=0)} \right ]</script><p>上式用来说明attention map是如何影响网络的训练的。对于正样本，我们从两个方面来加强目标的attention，首先就是增加$A_p$的均值，并减小方差，这样使得$A_p$的密度增大，同时变化减小（类似高原），其次就是减小$A_n$的均值，并增加方差，这样使得$A_n$的密度减小，变化增大（类似丘陵），分类器通过这两个约束可以提高true-positive，降低false-negative。同样的对于等式4，分类器可以提高true-negative，降低false-postive。通过attention map的约束，分类器能够提高准确率</p>
<h4 id="交互学习"><a href="#交互学习" class="headerlink" title="交互学习"></a>交互学习</h4><p><img src="/images/DAT/reciprocative_learning.png" alt="Attention map的对比"></p>
<p>将attention map加入Loss函数之后，我们就可以进行交互学习了。在每次迭代过程中，我们都会计算出输入的sample的attention map，它反映了分类器当前的注意力在哪儿。没有attention约束的分类器，往往只会聚焦于某些具有判别能力的区域，当物体产生很多大形变时，这些点并不能让我们有效的跟踪。而有了attention的约束，判别器会聚焦于所有能将目标和背景区分开的区域。如图所示，随着交互学习的进行，attention区域逐渐扩展到整个目标。</p>
<h3 id="跟踪过程"><a href="#跟踪过程" class="headerlink" title="跟踪过程"></a>跟踪过程</h3><h4 id="模型初始化"><a href="#模型初始化" class="headerlink" title="模型初始化"></a>模型初始化</h4><p>在第一帧时，我们在目标周围随机采集$N_1$个样本，根据与目标的IoU是否大于0.5划分为正负样本，按照之前的公式，训练$H_1$轮，来更新全卷积层的权重</p>
<h4 id="在线检测"><a href="#在线检测" class="headerlink" title="在线检测"></a>在线检测</h4><p>在上一帧预测的目标周围采集$N_2$个样本输入网络，选择得分最高的样本进行bounding box regression，作为在当前帧的检测结果</p>
<h4 id="模型更新"><a href="#模型更新" class="headerlink" title="模型更新"></a>模型更新</h4><p> 在每一帧，我们在预测的位置附近采集$N_2$个样本，同样根据与预测位置的IoU是否大于0.5划分为正负样本。然后，每隔$T$帧，按照公式训练$H_2$轮，来更新卷积层的权重</p>
<p> <img src="/images/DAT/contrast.png" alt="可视化"></p>
<p>作者将跟踪过程进行了可视化，如图所示，左右两栏分别代表baseline(没有交互学习)，以及本文方法（交互学习），第一栏为attention map，第二栏为score map，第三栏为跟踪结果，红框为预测框，绿框为groundtruth，可以看出，在一开始，两种方法相差不大，但是随着跟踪过程的进行，交互学习可以帮助分类器聚焦到整个目标区域，增强分类器的判断能力。最终，当与目标类似的干扰物体出现时，没有交互学习的方法就产生了漂移，而本文的方法则正确的检测到了结果。</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="实验细节"><a href="#实验细节" class="headerlink" title="实验细节"></a>实验细节</h4><p>特征提取网络为VGG-M，在整个跟踪过程中参数固定。全连接层是随机初始化并在跟踪过程中逐步更新的。作者使用GTX 1080时的速度为1 FPS。</p>
<h4 id="评测指标"><a href="#评测指标" class="headerlink" title="评测指标"></a>评测指标</h4><p>作者在OTB上使用的指标为distance precision (DP) 和 overlap success (OS)，DP使用的是20 pixel对应的准确度，OS使用的曲线下面积，此外还计算了CLE（中心平均误差）和 IoU为0.5时的比例（$OS_{0.5}$）。在VOT上，作者使用的指标为EAO，Ar，Rr</p>
<h4 id="Ablation-Studies"><a href="#Ablation-Studies" class="headerlink" title="Ablation Studies"></a>Ablation Studies</h4><p><img src="/images/DAT/table1.png" alt="表1"></p>
<p>作者首先在OTB2013上做了关了$\lambda$的实验，根据表1可以看出，$\lambda$在3到5之间的表现都很好，最终作者选择了5</p>
<p><img src="/images/DAT/table2.png" alt="表2"></p>
<p>由于attention map作为特征权重也可以提高分类器的表现，为了证明attention map约束的分类器更有效果，作者进行了对比实验，最终发现，attention map作为权重虽然可以提高分类器表现，但是提升幅度不如attention map作为约束</p>
<h4 id="与其他方法的对比"><a href="#与其他方法的对比" class="headerlink" title="与其他方法的对比"></a>与其他方法的对比</h4><p>作者在OTB-2013，OTB-2015，VOT-2016上与目前state-of-the-art的一些算法进行了对比，结果自然是比其他算法要高。</p>
<p><img src="/images/DAT/table3.png" alt="OTB结果1"></p>
<p><img src="/images/DAT/OTB.png" alt="OTB结果2"></p>
<p><img src="/images/DAT/VOT.png" alt="VOT结果"></p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>与现有的一些使用attention map作为feature weight的做法不同，本文从另一个角度使用attention map，将其作为一个约束项加入Loss函数中，从而让分类器在跟踪的过程中学会如何去attention，可以说是比较有新意的视角，本文的源码也已经放在了github上，有兴趣的同学可以自己尝试用一下。</p>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/paper-visual-tracking/" rel="tag"># paper, visual tracking</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/10/21/UPDT/" rel="next" title="论文笔记 - Unveiling the Power of Deep Tracking">
                <i class="fa fa-chevron-left"></i> 论文笔记 - Unveiling the Power of Deep Tracking
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="王国坤">
            
              <p class="site-author-name" itemprop="name">王国坤</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">tags</span>
                  
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/gkwangustc" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:yourname@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#背景"><span class="nav-number">2.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创新点"><span class="nav-number">3.</span> <span class="nav-text">创新点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#本文提出的方法"><span class="nav-number">4.</span> <span class="nav-text">本文提出的方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Attention"><span class="nav-number">4.1.</span> <span class="nav-text">Attention</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Attention的正则化"><span class="nav-number">4.2.</span> <span class="nav-text">Attention的正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#交互学习"><span class="nav-number">4.3.</span> <span class="nav-text">交互学习</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#跟踪过程"><span class="nav-number">5.</span> <span class="nav-text">跟踪过程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模型初始化"><span class="nav-number">5.1.</span> <span class="nav-text">模型初始化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#在线检测"><span class="nav-number">5.2.</span> <span class="nav-text">在线检测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#模型更新"><span class="nav-number">5.3.</span> <span class="nav-text">模型更新</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实验"><span class="nav-number">6.</span> <span class="nav-text">实验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#实验细节"><span class="nav-number">6.1.</span> <span class="nav-text">实验细节</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#评测指标"><span class="nav-number">6.2.</span> <span class="nav-text">评测指标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ablation-Studies"><span class="nav-number">6.3.</span> <span class="nav-text">Ablation Studies</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#与其他方法的对比"><span class="nav-number">6.4.</span> <span class="nav-text">与其他方法的对比</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#总结"><span class="nav-number">6.5.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright"> &copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">王国坤</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Mist</a></div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.5.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.5.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.5.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.5.0"></script>



  



  










  





  

  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

</body>
</html>
